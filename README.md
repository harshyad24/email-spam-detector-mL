

# ğŸš«ğŸ“¬ Building a Smart Email Spam Classifier with Machine Learning

## ğŸ§© Summary

Spam emails are not just annoyingâ€”theyâ€™re dangerous. From phishing links to fraudulent schemes, they pose a real threat to inbox security. In this blog, Iâ€™ll walk you through how I built an intelligent spam detection system using a real-world dataset of 10,000 emails. The goal was to distinguish between **spam** and **ham (legitimate)** messages using **machine learning and NLP techniques**. By the end, we achieved **100% accuracy** using Logistic Regressionâ€”while also interpreting which words made the most difference in decision-making.

---

## â“ Problem Statement

We receive countless emails daily. Some are from our teams, clients, or friendsâ€”and others try to **trick us** into clicking malicious links, revealing passwords, or buying fake products. Traditional rule-based spam filters struggle to keep up with evolving patterns.

### The challenge:

> Can we train a machine to understand the language of emailsâ€”and classify them as **spam or legitimate (ham)**â€”just by analyzing the email content?

---

## ğŸ§  Our Approach

To build an effective spam detection model, we needed a robust and realistic dataset. Thankfully, I used a **real-world email forensics dataset** with 10,000 messages, each labeled as "spam" or "ham."

The core steps in our machine learning pipeline were:

1. **Preprocessing** the email text (cleaning, normalizing).
2. **Vectorizing** the text into numerical features using **TF-IDF**.
3. Training **two models**:

   * Logistic Regression
   * Multinomial Naive Bayes
4. **Evaluating** the results on a test set.
5. Extracting the **most influential words** using model coefficients.
6. Allowing for **custom email classification** based on user input.

---

## ğŸ› ï¸ Solution in Action

### ğŸ§¹ Preprocessing

We started by:

* Removing punctuation, HTML tags, and lowercasing text
* Encoding the labels (`spam = 1`, `ham = 0`)
* Splitting the data into **training (80%)** and **test (20%)**

### ğŸ“Š Feature Engineering

To convert raw text into model-friendly input, we used **TF-IDF vectorization**. This method captures the importance of words based on how frequently they appear across all emails.

### ğŸ¤– Models Used

* **Logistic Regression**: A solid baseline classifier for binary tasks
* **Multinomial Naive Bayes**: Known to perform well on text data

Both models were trained and evaluated using:

* **Accuracy**
* **Precision & Recall**
* **Confusion Matrix**

---

## ğŸ“ˆ Results & Findings

### ğŸš€ Logistic Regression Results:

```
Accuracy:       100%
Precision:      1.00
Recall:         1.00
F1-Score:       1.00
```

**Confusion Matrix:**

```
[[1682    0]
 [   0  318]]
```

The model achieved **perfect classification** on unseen test dataâ€”an exciting result! However, such high scores also warranted caution against possible **data leakage** or overly obvious spam clues.

---

### ğŸ” Interpreting the Model

We extracted the most influential words using model coefficients. Here's what we discovered:

# ğŸ”´ Top Spam Words:



![Spam Word Cloud](https://github.com/harshyad24/email-spam-detector-mL/blob/main/spam_wordcloud.png?raw=true)







```
new, account, login, delayed, click, offer, claim, urgent
```

These words convey urgency or deceitâ€”common in scam emails.

# ğŸŸ¢ Top Ham Words:

![Ham Word Cloud](https://github.com/harshyad24/email-spam-detector-mL/blob/main/ham_wordcloud.png?raw=true)

```
software, team, thank, feedback, meeting, project, reminder
```

Words typical of professional or collaborative environments.

We also visualized these with bar plots to better understand what drives the modelâ€™s decisions.

---

## ğŸ“¬ Custom Email Detection

I added a feature to allow real-time predictions. You can input any email text, and the model will classify it as **spam** or **ham** in a flash.

Example:

```python
email = "Your account has been flagged. Click here to verify."
â†’ Prediction: Spam
```

---

## ğŸ§  Lessons & Takeaways

* **Text preprocessing** and **TF-IDF** are powerful tools for extracting meaning from language.
* Logistic Regression can perform surprisingly well on clean, structured data.
* Always **interpret your models**â€”understanding *why* decisions are made builds trust.
* Be careful of overly perfect resultsâ€”they may mask underlying biases or shortcuts in the data.

---

## ğŸŒ± What's Next?

* Deploy the model as a **web app using Streamlit or Flask**
* Add support for **email headers, metadata, or attachments**
* Experiment with deep learning models like **LSTM** or **BERT**

---

## ğŸ§¾ Final Thoughts

This project highlights the intersection of **NLP and cybersecurity**â€”where machine learning is already playing a key role in protecting digital communication. Whether you're a developer, researcher, or curious learner, this project offers practical insight into spam detection using real-world data.
